# Объяснение пайплайна full_demo_pipeline.ipynb для QA

Этот документ описывает логику работы Jupyter-ноутбука `full_demo_pipeline.ipynb` простым языком. Цель — помочь QA-специалистам понять процесс для дальнейшего написания автотестов, в том числе с использованием фреймворка DeepEval.

## 1. Общее описание пайплайна

Пайплайн представляет собой комплексный процесс, который решает две основные задачи с помощью AI-модели от Yandex (YandexGPT):

1.  **Классификация звонков:** Автоматическое определение тематики телефонного разговора (например, "Спам", "Вакансии", "Покупка").
2.  **Суммаризация звонков:** Создание краткого пересказа (ре��юме) содержания разговора.

Весь процесс можно разбить на следующие этапы:
- **Подготовка:** Загрузка библиотек, аутентификация в сервисах Yandex.
- **Анализ данных:** Изучение и визуализация исходных данных (текстовых расшифровок звонков).
- **Обучение модели (Fine-tuning):** Дообучение базовой модели YandexGPT на наших данных, чтобы она лучше понимала специфику звонков.
- **Оценка качества (Evaluation):** Проверка, насколько точно обученная модель классифицирует звонки.
- **Пример использования для суммаризации:** Демонстрация того, как модель может делать краткий пересказ текста.

---

## 2. Подготовка и анализ данных (Data Overview)

На этом этапе происходит загрузка и изучение данных, на которых будет обучаться и тестирова��ься модель.

### Что происходит?

1.  **Загрузка данных:**
    - Скрипт читает текстовые файлы (`.txt`) из папки `../data/Звонки/`.
    - В этой папке есть подпапки, названия которых соответствуют категориям звонков ("Спам", "Вакансии" и т.д.).
    - Вся информация загружается в специальную таблицу (Pandas DataFrame), где каждая строка — это один звонок со следующими полями:
        - `type`: Категория звонка (название папки).
        - `content`: Полная текстовая расшифровка разговора.
        - `word_count`: Количество слов в разговоре.

2.  **Анализ данных:**
    - Строятся графики, чтобы понять характеристики данных:
        - **Распределение длины звонков:** Насколько длинные или короткие тексты разговоров. Это помогает выявить аномалии (например, пуст��е файлы или слишком длинные разговоры).
        - **Распределение по классам:** Сколько звонков каждого типа у нас есть. Это важно для понимания, сбалансированы ли данные. Если какого-то класса звонков очень мало, модели будет сложнее его изучить.

### На что обратить внимание QA?

- **Источник данных:** Данные должны быть корректно загружены из папки `../data/Звонки/`.
- **Целостность данных:** Проверить, что нет пустых файлов или файлов с некорректным содержимым, которые могут привести к ошибкам. В ноутбуке есть примеры фильтрации звонков с количеством слов меньше 100 — это один из способов отсеять "мусорные" данные.
- **Соответствие классов:** В ноутбуке есть ячейка с текстом, где сравниваются имеющиеся классы ��вонков с теми, что описаны в PRD. Это важный момент для тестирования: модель должна классифицировать звонки в соответствии с бизнес-требованиями.

---

## 3. Обучение модели (Fine-tuning)

Это ключевой этап, на котором мы "адаптируем" базовую AI-модель под нашу конкретную задачу.

### Что происходит?

1.  **Подготовка данных для обучения:**
    - Создается новый файл `calls_for_finetune.jsonl`.
    - В этот файл данные записываются в специальном формате, который понятен модели YandexGPT: каждая строка содержит `{"input": "текст звонка", "output": "категория звонка"}`.

2.  **Запуск процесса дообучения:**
    - С помощью Yandex Cloud ML SDK запускается процесс дообучения (`fine-tuning`) модели `yandexgpt-lite`.
    - Модели "показывают" примеры текстов звонков и пра��ильные ответы (категории), чтобы она научилась находить закономерности.
    - Процесс занимает некоторое время. По его завершении мы получаем идентификатор нашей новой, дообученной модели.

### На что обратить внимание QA?

- **Формат данных:** Входной файл `calls_for_finetune.jsonl` должен строго соответствовать формату `JSON Lines`. Ошибки в формате приведут к сбою обучения.
- **Качество обучающих данных:** "Мусор на входе — мусор на выходе". Если в обучающих данных много ошибок (неправильно размеченные категории, опечатки), модель научится этим ошибкам.
- **Тест-кейсы для DeepEval:**
    - **Consistency (Последовательность):** Можно создать несколько похожих по смыслу, но разных по формулировкам текстов звонков и проверить, что модель классифицирует их одинаково.
    - **Bias (Предвзятость):** Проверить, не отдает ли модель предпочтение какому-то одному классу, особенно если он доминирует в обучающих данных.

---

## 4. Оценка качества модели (Evaluation)

После обучения нужно понять, насколько хорошо модель справляется со своей задачей на данных, которые она еще не видела.

### Что происходит?

1.  **Разделение данных:**
    - Исходные данные делятся на две части: **обучающую** (80%) и **тестовую** (20%).
    - Модель обучается на первой части, а проверяется на второй. Это гарантирует, что мы тестируем её способность обобщать, а не просто запоминать.
    - Тестовые данные сохраняются в файл `calls_for_eval.jsonl`.

2.  **Запуск оценки:**
    - Запускается задача оценки, где дообученная модель пытается предсказать категорию для каждого звонка из тестового набора.
    - Результаты предсказаний сравниваются с реальными (правильными) категориями.

3.  **Анализ результатов:**
    - **Accuracy (Точность):** Основная метрика, которая показывает процент правильных ответов.
    - **Confusion Matrix (Матрица ошибок):** Это таблица, которая наглядно показывает, какие классы модель путает между собой. Например, она может часто путать "Спам" и "Коммерческие предложения".

### На что обратить внимание QA?

- **Разделение данных:** Важно, чтобы в тестовый набор не попали данные из обучающего.
- **Метрики:**
    - **Accuracy:** Насколько высок этот показатель? Если он низкий, модель работает плохо.
    - **Confusion Matrix:** Анализ матрицы ошибок — это золотая жила для QA. Она показывает слабые места модели. Если модель часто путает классы А и Б, нужно создать больше тестов именно на различие этих двух классов.
- **Тест-кейсы для DeepEval:**
    - **Factual Accuracy (Фактическая точность):** Для каждого примера из тестового набора можно проверить, совпадает ли предсказание модели (`actual_output`) с правильным ответом (`expected_output`).
    - **Answer Relevancy (Релевантность ответа):** Хотя это больше для генеративных задач, можно адаптировать: насколько предсказанная категория соответствует содержанию звонка.

---

## 5. Суммаризация (пересказ) текста

Этот раздел демонстрирует еще одну возможность модели — создание краткого содержания текста.

### Что происходит?

1.  **Подготовка данных:**
    - Загружаются данные из папки `../data/Пересказ/`, где есть файлы с полными текстами и их краткими версиями (summary).
2.  **Генерация пересказа:**
    - Берется один пример звонка.
    - Модели дается инструкция (промпт): "Сделай краткий пересказ следующего диалога".
    - Модель генерирует свой вариант краткого содержания.
3.  **Сравнение:**
    - Сгенерированный моделью пересказ сравнивается с эталонным (заранее подготовленным человеком).

### На что обратить внимание QA?

- **Качество суммаризации:**
    - Не упускает ли модель важные детали?
    - Не добавляет ли она информацию, которой не было в исходном тексте (галлюцинации)?
    - Является ли пересказ связным и понятным?
- **Тест-кейсы для DeepEval:**
    - **Summarization:** Это встроенная метрика в DeepEval, которая идеально подходит для этой задачи. Она оценивает, насколько сгенерированный текст покрывает основное содержание исходного.
    - **Hallucination (Галлюцинации):** Проверка на то, не выдумывает ли модель факты.
    - **Faithfulness (Верность источнику):** Убедиться, что вся информация в пересказе подтверждается исходным текстом.

Надеюсь, это объяснение поможет вам в подготовке тестов!
